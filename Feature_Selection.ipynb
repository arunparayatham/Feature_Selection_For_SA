{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords #used in stopwords removal\n",
    "stop_wrds=stopwords.words('english')\n",
    "stop_wrds.remove('not')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import scipy.stats as ss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorization():\n",
    "    #this class creates TFIDF vectors for the given set of documents\n",
    "    \n",
    "    def create_TFIDF_vectors(self, documents, n_grams, maximum_df=1.0, minimum_df=1, maximum_features=2000):\n",
    "        '''this function returns creates TFIDF scores matrix and features'''\n",
    "        if maximum_features != None:\n",
    "            vectorizer = TfidfVectorizer(stop_words=stop_wrds, ngram_range=n_grams, max_df=maximum_df, min_df=minimum_df, max_features=maximum_features)\n",
    "        else:\n",
    "            vectorizer = TfidfVectorizer(stop_words=stop_wrds, ngram_range=n_grams)\n",
    "            \n",
    "        #vectorizer = TfidfVectorizer(stop_words=stop_wrds, ngram_range=(1, 1))\n",
    "        tfidf_matrix=vectorizer.fit_transform(documents)\n",
    "\n",
    "        feature_index = [tfidf_matrix[i,:].nonzero()[1] for i in range(len(documents))]\n",
    "\n",
    "        feature_names=vectorizer.get_feature_names()\n",
    "        features = [[feature_names[j] for j in i] for i in feature_index]\n",
    "\n",
    "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns = vectorizer.get_feature_names())\n",
    "        #tfidf_scores = zip([feature_names[i] for i in feature_index], [tfidf_matrix[0, x] for x in feature_index])\n",
    "\n",
    "        return tfidf_matrix,feature_index,features,feature_names,tfidf_df\n",
    "\n",
    "\n",
    "    def get_feature_data(self, data, n_grams, max_df, min_df, max_features):\n",
    "        '''this function returns features and their corresponding tfidf scores along with the target class'''\n",
    "    \n",
    "        classes=list(data['sentiment_class'])\n",
    "        reviews=list(data['text'])\n",
    "\n",
    "        tfidf_matrix,feature_index,features,feature_names,tfidf_df = self.create_TFIDF_vectors(reviews, n_grams, max_df, min_df, max_features)\n",
    "        features_df = pd.DataFrame(feature_names,columns=['features'])\n",
    "        tfidf_df.to_csv('results/tfidf_scores.csv',index=False,header=tfidf_df.columns)\n",
    "\n",
    "        reviews_df = pd.DataFrame(reviews,columns=['review'])\n",
    "        classes_df = pd.DataFrame(classes,columns=['class'])\n",
    "\n",
    "        feature_data_df=pd.concat([reviews_df,tfidf_df,classes_df],axis=1)\n",
    "        feature_data_df.to_csv('results/feature_data.csv',index=False,header=feature_data_df.columns)\n",
    "\n",
    "        return feature_data_df, tfidf_df  \n",
    "    \n",
    "    \n",
    "    def split_X_and_y(self, tfidf_df, feature_data_df):\n",
    "        y = pd.get_dummies(feature_data_df['class'], prefix = 'class')\n",
    "        if 'class' in y.columns.to_list():\n",
    "            y=y.drop(columns=['class'],axis=1)\n",
    "        X = tfidf_df\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OddsRatio():\n",
    "    \n",
    "    def find_odds_ratio(self, X, containing, target_class):\n",
    "        \n",
    "        odds_ratio_dict = {}\n",
    "        features = list(X.columns)\n",
    "        target_values = target_class.tolist()\n",
    "        for feature_index in range(len(features)):\n",
    "            a= list(X.iloc[:,feature_index])\n",
    "            b=containing[features[feature_index]]\n",
    "            \n",
    "            p = len([i for i in b if target_class[i]==1]) #no. of positive reviews with the feature word\n",
    "            q = len(b) #no. of reviews containing feature word\n",
    "            r = target_values.count(1) - p\n",
    "            s=len(a)-len(b) #no. of reviews not containing feature word\n",
    "\n",
    "            odds_ratio = (p/q) / (r/s)\n",
    "            odds_ratio_dict[X.columns[feature_index]]=odds_ratio\n",
    "\n",
    "        return odds_ratio_dict\n",
    "    \n",
    "    def odds_ratio_for_all_classes(self, X, y, containing):\n",
    "        odds_ratio_df = pd.DataFrame()\n",
    "        odds_ratio_df = pd.concat([odds_ratio_df,pd.DataFrame(X.columns.to_list())], axis=1)\n",
    "        \n",
    "        for i in range(len(y.columns)):\n",
    "            odds_ratio = self.find_odds_ratio(X,containing,y.iloc[:,i])\n",
    "            odds = pd.DataFrame(odds_ratio.values())\n",
    "            odds_ratio_df = pd.concat([odds_ratio_df, odds], axis=1)\n",
    "        \n",
    "        odds_ratio_df.columns = ['feature_word'] + y.columns.to_list()\n",
    "        odds_ratio_df.to_csv('results/odds_ratio.csv',index = False)\n",
    "        \n",
    "        return odds_ratio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class Features():\n",
    "    \n",
    "    # PEARSON CORRELATION\n",
    "    def cor_selector(self, X, y,num_feats):\n",
    "        cor_list = []\n",
    "        feature_name = X.columns.tolist()\n",
    "\n",
    "        for i in X.columns.tolist(): # calculate the correlation with y for each feature\n",
    "            cor = np.corrcoef(X[i], y)[0, 1]\n",
    "            cor_list.append(cor)\n",
    "       \n",
    "        cor_list = [0 if np.isnan(i) else i for i in cor_list]  # replace NaN with 0\n",
    "        cor_feature = X.iloc[:,np.argsort(cor_list)[-num_feats:]].columns.tolist()[::-1] # feature name\n",
    "        cor_support = [True if i in cor_feature else False for i in feature_name] # feature selection? 0 for not select, 1 for select\n",
    "\n",
    "        return cor_support, cor_feature, cor_list\n",
    "    \n",
    "    def getPearsonCorrelationFeatures(self, X, y, num_feats,frequency_dict):\n",
    "        pearson_features_df = pd.DataFrame()\n",
    "            \n",
    "        for i in range(len(y.columns)):\n",
    "            cor_support, cor_feature, cor_list = self.cor_selector(X,y.iloc[:,i],num_feats)\n",
    "            cor_feature_df = pd.DataFrame(cor_feature)\n",
    "            \n",
    "            frequency_list =[]\n",
    "            for feature in cor_feature:\n",
    "                frequency_list.append(frequency_dict[feature])\n",
    "            frequency_df = pd.DataFrame(frequency_list)\n",
    "            pearson_features_df = pd.concat([pearson_features_df, cor_feature_df, frequency_df],axis=1)\n",
    "            \n",
    "        #pearson_features_df.columns = y.columns.to_list()\n",
    "        columns_list = []\n",
    "        for column in y.columns.to_list():\n",
    "            columns_list.append(column)\n",
    "            columns_list.append(column+'_frequency')\n",
    "            \n",
    "        pearson_features_df.columns = columns_list\n",
    "        \n",
    "        pearson_features_df.to_csv('results/pearson_features.csv',index=False)\n",
    "        \n",
    "        return pearson_features_df\n",
    "    \n",
    "    def getChiSquaredFeatures(self,X,y,no_features):\n",
    "        X_norm = MinMaxScaler().fit_transform(X)\n",
    "        \n",
    "        chi_selector = SelectKBest(chi2, k=no_features)\n",
    "        chi_selector.fit(X_norm, y)\n",
    "\n",
    "        chi_support = chi_selector.get_support()\n",
    "        chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "\n",
    "        return chi_support, chi_feature\n",
    "    \n",
    "    def getChiSquaredCorrelationFeatures(self,X,y,num_feats,frequency_dict):\n",
    "        chisquare_features_df = pd.DataFrame()\n",
    "            \n",
    "        for i in range(len(y.columns)):\n",
    "            chi_support, chi_feature = self.getChiSquaredFeatures(X,y.iloc[:,i],num_feats)\n",
    "            chi_feature_df = pd.DataFrame(chi_feature)\n",
    "            \n",
    "            frequency_list =[]\n",
    "            for feature in chi_feature:\n",
    "                frequency_list.append(frequency_dict[feature])\n",
    "            frequency_df = pd.DataFrame(frequency_list)\n",
    "            \n",
    "            chisquare_features_df = pd.concat([chisquare_features_df, chi_feature_df,frequency_df],axis=1)\n",
    "        \n",
    "        #chisquare_features_df.columns = y.columns.to_list()\n",
    "        columns_list = []\n",
    "        for column in y.columns.to_list():\n",
    "            columns_list.append(column)\n",
    "            columns_list.append(column+'_frequency')\n",
    "            \n",
    "        chisquare_features_df.columns = columns_list\n",
    "        chisquare_features_df.to_csv('results/chisquare_features.csv',index=False)\n",
    "        \n",
    "        return chisquare_features_df\n",
    "    \n",
    "    def findRFEFeatures(self,X,y,no_features):\n",
    "        X_norm = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "        rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=no_features, step=100, verbose=0)\n",
    "        rfe_selector.fit(X_norm, y)\n",
    "        rfe_support = rfe_selector.get_support()\n",
    "        rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
    "\n",
    "        return rfe_support, rfe_feature\n",
    "    \n",
    "    def getRFEFeatures(self,X,y,num_feats):\n",
    "        rfe_features_df = pd.DataFrame()\n",
    "            \n",
    "        for i in range(len(y.columns)):\n",
    "            rfe_support, rfe_feature = self.findRFEFeatures(X,y.iloc[:,i],num_feats)\n",
    "            rfe_feature_df = pd.DataFrame(rfe_feature)\n",
    "            frequency_list =[]\n",
    "            for feature in rfe_feature:\n",
    "                frequency_list.append(frequency_dict[feature])\n",
    "            frequency_df = pd.DataFrame(frequency_list)\n",
    "            rfe_features_df = pd.concat([rfe_features_df, rfe_feature_df,frequency_df],axis=1)\n",
    "        \n",
    "        #rfe_features_df.columns = y.columns.to_list()\n",
    "        columns_list = []\n",
    "        for column in y.columns.to_list():\n",
    "            columns_list.append(column)\n",
    "            columns_list.append(column+'_frequency')\n",
    "            \n",
    "        rfe_features_df.columns = columns_list\n",
    "        rfe_features_df.to_csv('results/rfe_features.csv',index=False)\n",
    "        \n",
    "        return rfe_features_df\n",
    "    \n",
    "    def findLRFeatures(self,X,y,no_features):\n",
    "        X_norm = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "        embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l2\"), max_features=no_features)\n",
    "        embeded_lr_selector.fit(X_norm, y)\n",
    "\n",
    "        embeded_lr_support = embeded_lr_selector.get_support()\n",
    "        embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "\n",
    "        return embeded_lr_support, embeded_lr_feature\n",
    "    \n",
    "    def getLRFeatures(self,X,y,num_feats):\n",
    "        lr_features_df = pd.DataFrame()\n",
    "            \n",
    "        for i in range(len(y.columns)):\n",
    "            lr_support, lr_feature = self.findLRFeatures(X,y.iloc[:,i],num_feats)\n",
    "            lr_feature_df = pd.DataFrame(lr_feature)\n",
    "            frequency_list =[]\n",
    "            for feature in lr_feature:\n",
    "                frequency_list.append(frequency_dict[feature])\n",
    "            frequency_df = pd.DataFrame(frequency_list)\n",
    "            lr_features_df = pd.concat([lr_features_df, lr_feature_df,frequency_df],axis=1)\n",
    "        \n",
    "        #lr_features_df.columns = y.columns.to_list()\n",
    "        columns_list = []\n",
    "        for column in y.columns.to_list():\n",
    "            columns_list.append(column)\n",
    "            columns_list.append(column+'_frequency')\n",
    "            \n",
    "        lr_features_df.columns = columns_list\n",
    "        lr_features_df.to_csv('results/lr_features.csv',index=False)\n",
    "        \n",
    "        return lr_features_df\n",
    "    \n",
    "    def findRFCFeatures(self,X,y,no_features):\n",
    "        embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=10), max_features=no_features)\n",
    "        embeded_rf_selector.fit(X, y)\n",
    "\n",
    "        embeded_rf_support = embeded_rf_selector.get_support()\n",
    "        embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "        return embeded_rf_support, embeded_rf_feature\n",
    "    \n",
    "    def getRFCFeatures(self,X,y,num_feats):\n",
    "        rfc_features_df = pd.DataFrame()\n",
    "            \n",
    "        for i in range(len(y.columns)):\n",
    "            rfc_support, rfc_feature = self.findRFCFeatures(X,y.iloc[:,i],num_feats)\n",
    "            rfc_feature_df = pd.DataFrame(rfc_feature)\n",
    "            frequency_list =[]\n",
    "            for feature in rfc_feature:\n",
    "                frequency_list.append(frequency_dict[feature])\n",
    "            frequency_df = pd.DataFrame(frequency_list)\n",
    "            rfc_features_df = pd.concat([rfc_features_df, rfc_feature_df,frequency_df],axis=1)\n",
    "        \n",
    "        #rfc_features_df.columns = y.columns.to_list()\n",
    "        columns_list = []\n",
    "        for column in y.columns.to_list():\n",
    "            columns_list.append(column)\n",
    "            columns_list.append(column+'_frequency')\n",
    "            \n",
    "        rfc_features_df.columns = columns_list\n",
    "        rfc_features_df.to_csv('results/rfc_features.csv',index=False)\n",
    "        \n",
    "        return rfc_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelection():\n",
    "    \n",
    "    def __init__(self, object_dict):\n",
    "        print(object_dict['preprocessed_data'])\n",
    "        self.preprocessed_data = pd.read_csv(object_dict['preprocessed_data'])\n",
    "        \n",
    "        if not os.path.exists(object_dict['preprocessed_data']):\n",
    "            raise Exception('------Perform preprocessing before performing Feature Selection!-----')\n",
    "            \n",
    "            \n",
    "        self.number_of_features = int(object_dict['no_of_features'])\n",
    "        import ast\n",
    "        self.n_gram_range = ast.literal_eval(object_dict['n_gram_range'])\n",
    "        \n",
    "        self.max_df = ast.literal_eval(object_dict['max_df'])\n",
    "        self.min_df = ast.literal_eval(object_dict['min_df'])\n",
    "        self.max_features = int(object_dict['max_features'])\n",
    "        \n",
    "        vectorization = Vectorization()\n",
    "        \n",
    "        self.feature_data_df, self.tfidf_df = vectorization.get_feature_data(self.preprocessed_data, self.n_gram_range, self.max_df, self.min_df, self.max_features)\n",
    "        self.X, self.y = vectorization.split_X_and_y(self.tfidf_df, self.feature_data_df)\n",
    "        \n",
    "        self.indices = self.store_indices(self.X)\n",
    "        self.frequency_dict = self.count_frequency(self.indices,object_dict)\n",
    "        \n",
    "        features = Features()\n",
    "        if object_dict['pearson']=='True':\n",
    "            self.pearson_features_df = features.getPearsonCorrelationFeatures(self.X, self.y, self.number_of_features, self.frequency_dict)\n",
    "        if object_dict['chi_square']=='True':\n",
    "            self.chisquare_features_df = features.getChiSquaredCorrelationFeatures(self.X, self.y, self.number_of_features, self.frequency_dict)\n",
    "        if object_dict['rfe']=='True':\n",
    "            self.rfe_features_df = features.getRFEFeatures(self.X, self.y, self.number_of_features, self.frequency_dict)\n",
    "        if object_dict['lr']=='True':\n",
    "            self.lr_features_df = features.getLRFeatures(self.X, self.y, self.number_of_features, self.frequency_dict)\n",
    "        if object_dict['rfc']=='True':\n",
    "            self.rfc_features_df = features.getRFCFeatures(self.X, self.y, self.number_of_features, self.frequency_dict)\n",
    "        \n",
    "        odds_ratio = OddsRatio()\n",
    "        \n",
    "        if object_dict['odds_ratio']=='True':\n",
    "            self.odds_ratio_df = odds_ratio.odds_ratio_for_all_classes(self.X, self.y, self.indices)\n",
    "        \n",
    "    def create_preprocessed_data(self,obj,filename,column_names):\n",
    "        classes_df = pd.DataFrame(obj.classes)\n",
    "        reviews_df = pd.DataFrame(obj.reviews)\n",
    "\n",
    "        x=pd.concat([classes_df , reviews_df] , axis=1)\n",
    "        x.columns=column_names\n",
    "        x.to_csv(filename,index=False)\n",
    "    \n",
    "    def store_indices(self,X):\n",
    "        indices = {}\n",
    "        features = list(X.columns)\n",
    "        for feature_index in range(len(features)):\n",
    "            a = list(X.iloc[:,feature_index])\n",
    "            containing = [i for i,x in enumerate(a) if x!=0]\n",
    "            indices[features[feature_index]] = containing\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def count_frequency(self,containing,obj_dict):\n",
    "        features = list(pd.read_csv('results/tfidf_scores.csv').columns)\n",
    "        reviews = list(pd.read_csv(object_dict['preprocessed_data'])['text'])\n",
    "        \n",
    "        counts_dict = {}\n",
    "        for i in features:\n",
    "            indices = containing[i]\n",
    "            count =0\n",
    "            for j in indices:\n",
    "                count+=reviews[j].count(i)\n",
    "            counts_dict[i] = count\n",
    "\n",
    "        df = pd.DataFrame.from_dict(counts_dict,orient='index')\n",
    "        words_df = pd.DataFrame(counts_dict.keys())\n",
    "        counts_df = pd.DataFrame(counts_dict.values())\n",
    "\n",
    "        frequency_df = pd.concat([words_df, counts_df],axis=1)\n",
    "        frequency_df.columns = ['word','frequency']\n",
    "        frequency_df.to_csv(object_dict['raw_data'].split('.')[0]+'_word_frequency.csv',index=False)\n",
    "        \n",
    "        return counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run FeatureSelectionConfiguration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw_data': 'IMDBtrainProcessed.csv', 'preprocessed_data': 'IMDBtrainProcessed_PreProcessed.csv', 'no_of_features': '100', 'n_gram_range': '(1, 2)', 'idf_weighing': 'False', 'max_df': '500', 'min_df': '100', 'max_features': '2000', 'pearson': 'True', 'chi_square': 'True', 'rfe': 'True', 'lr': 'True', 'rfc': 'True', 'odds_ratio': 'True'}\n",
      "IMDBtrainProcessed_PreProcessed.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "getRFEFeatures() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-7c422f0e421f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFeatureSelection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-69904efbee65>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, object_dict)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchisquare_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetChiSquaredCorrelationFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequency_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobject_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rfe'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfe_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetRFEFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequency_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobject_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLRFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequency_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getRFEFeatures() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from configparser import ConfigParser\n",
    "    \n",
    "    config = ConfigParser()\n",
    "    config.read('feature_selection.ini')\n",
    "    \n",
    "    object_dict = dict()\n",
    "\n",
    "    object_dict['raw_data'] = config['FeatureSelection']['raw_data']\n",
    "    object_dict['preprocessed_data'] = object_dict['raw_data'].split('.')[0] + '_PreProcessed.csv'\n",
    "    \n",
    "    object_dict['no_of_features'] = config['FeatureSelection']['number_of_features']\n",
    "    \n",
    "    object_dict['n_gram_range'] = config['FeatureSelection']['n_gram_range']\n",
    "    object_dict['idf_weighing'] = config['FeatureSelection']['idf_weighing']\n",
    "    object_dict['max_df'] = config['FeatureSelection']['max_df']\n",
    "    object_dict['min_df'] = config['FeatureSelection']['min_df']\n",
    "    object_dict['max_features'] = config['FeatureSelection']['max_features']\n",
    "    \n",
    "    object_dict['pearson'] = config['FeatureSelection']['pearson_correlation']\n",
    "    object_dict['chi_square'] = config['FeatureSelection']['chi_square_correlation']\n",
    "    object_dict['rfe'] = config['FeatureSelection']['recursive_feature_elimination']\n",
    "    object_dict['lr'] = config['FeatureSelection']['lasso_regression']\n",
    "    object_dict['rfc'] = config['FeatureSelection']['random_forest_classifier']\n",
    "    object_dict['odds_ratio'] = config['FeatureSelection']['odds_ratio']\n",
    "    \n",
    "    print(object_dict)\n",
    "    \n",
    "    import os\n",
    "    try:\n",
    "        os.mkdir('results')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    result = FeatureSelection(object_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
